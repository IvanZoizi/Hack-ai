{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "685b32c7",
      "metadata": {
        "id": "685b32c7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cbook as cbook\n",
        "from matplotlib.path import Path\n",
        "from matplotlib.patches import PathPatch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b345dea",
      "metadata": {
        "id": "1b345dea"
      },
      "source": [
        "# shit EDA and data engineering shit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P53VdcRU_kPU",
        "outputId": "3e27e299-3d43-4718-f269-b7c0016a09e9"
      },
      "id": "P53VdcRU_kPU",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR = '/content/drive/MyDrive/find_polar_bear'"
      ],
      "metadata": {
        "id": "WzKGrrWf_jp5"
      },
      "id": "WzKGrrWf_jp5",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f60b7ae4",
      "metadata": {
        "id": "f60b7ae4"
      },
      "source": [
        "# Setting up data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83eca9f1",
      "metadata": {
        "scrolled": true,
        "id": "83eca9f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38037c72-4390-49f4-898a-7bb2b703564f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catalyst\n",
            "  Downloading catalyst-22.4-py2.py3-none-any.whl (446 kB)\n",
            "\u001b[K     |████████████████████████████████| 446 kB 27.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from catalyst) (1.12.1+cu113)\n",
            "Collecting tensorboardX>=2.1.0\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 68.9 MB/s \n",
            "\u001b[?25hCollecting accelerate>=0.5.1\n",
            "  Downloading accelerate-0.12.0-py3-none-any.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting hydra-slayer>=0.4.0\n",
            "  Downloading hydra_slayer-0.4.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from catalyst) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from catalyst) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate>=0.5.1->catalyst) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate>=0.5.1->catalyst) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate>=0.5.1->catalyst) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate>=0.5.1->catalyst) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=2.1.0->catalyst) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX>=2.1.0->catalyst) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->catalyst) (4.1.1)\n",
            "Installing collected packages: tensorboardX, hydra-slayer, accelerate, catalyst\n",
            "Successfully installed accelerate-0.12.0 catalyst-22.4 hydra-slayer-0.4.0 tensorboardX-2.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.7.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.6.0.66)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (6.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (4.1.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Name: catalyst\n",
            "Version: 22.4\n",
            "Summary: Catalyst. Accelerated deep learning R&D with PyTorch.\n",
            "Home-page: https://github.com/catalyst-team/catalyst\n",
            "Author: Sergey Kolesnikov\n",
            "Author-email: scitator@gmail.com\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: torch, numpy, tensorboardX, accelerate, tqdm, hydra-slayer\n",
            "Required-by: \n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 28.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install catalyst\n",
        "!pip install albumentations --user\n",
        "!pip show catalyst\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e0854b3a",
      "metadata": {
        "id": "e0854b3a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import collections\n",
        "import time \n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "train_on_gpu = True\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
        "\n",
        "# import albumentations as albu\n",
        "# from albumentations import torch as AT\n",
        "\n",
        "# import catalyst\n",
        "# from catalyst.data import Augmentor\n",
        "# from catalyst.dl import utils\n",
        "# from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\n",
        "from catalyst.runners import SupervisedRunner\n",
        "# from catalyst.contrib.models.segmentation import Unet\n",
        "from catalyst.callbacks import DiceCallback, EarlyStoppingCallback, CheckpointCallback\n",
        "\n",
        "#import segmentation_models_pytorch as smp\n",
        "\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import time\n",
        "import tqdm\n",
        "import random\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm as tq\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8dd34a16",
      "metadata": {
        "id": "8dd34a16"
      },
      "outputs": [],
      "source": [
        "class CloudDataset(Dataset):\n",
        "    def __init__(self, img_ids, datatype: str = 'train',\n",
        "                 transforms = transforms.Compose([\n",
        "                                transforms.ToPILImage(),\n",
        "                                transforms.Resize((256, 256)),\n",
        "                                transforms.ToTensor()]),\n",
        "                preprocessing=None):\n",
        "        \n",
        "        self.img_ids = img_ids\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(os.path.join(WORKING_DIR, f'bears_cropped/bears/{idx}.jpg'))\n",
        "        try:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        except:\n",
        "            raise IndexError\n",
        "        mask = cv2.imread(os.path.join(WORKING_DIR, f'bears_cropped/masks/{idx}.png'))\n",
        "        img = self.transforms(img)\n",
        "        mask = self.transforms(mask)[:1, :, :]\n",
        "        mask = (mask > 0.5).float()\n",
        "        if self.preprocessing:\n",
        "            preprocessed = self.preprocessing(image=img, mask=mask)\n",
        "            img = preprocessed['image']\n",
        "            mask = preprocessed['mask']\n",
        "        return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "52ff4816",
      "metadata": {
        "id": "52ff4816"
      },
      "outputs": [],
      "source": [
        "class double_conv(nn.Module):\n",
        "    \"\"\"(conv => BN => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(nn.MaxPool2d(2), double_conv(in_ch, out_ch))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))\n",
        "        \n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256, False)\n",
        "        self.up2 = up(512, 128, False)\n",
        "        self.up3 = up(256, 64, False)\n",
        "        self.up4 = up(128, 64, False)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "00b64bb7",
      "metadata": {
        "id": "00b64bb7"
      },
      "outputs": [],
      "source": [
        "model = UNet(n_channels=3, n_classes=1).float()\n",
        "train_on_gpu = True\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(os.path.join(WORKING_DIR, 'model2.pt'), map_location=torch.device('cuda') if train_on_gpu else torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p7OXDI_379x",
        "outputId": "5d349cd7-9058-458e-9966-5a4b3731850b"
      },
      "id": "7p7OXDI_379x",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95659f09",
      "metadata": {
        "id": "95659f09"
      },
      "source": [
        "# training "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_bears(img):\n",
        "    if torch.is_tensor(img):\n",
        "        img = img.numpy()\n",
        "    elif not isinstance(img, np.ndarray):\n",
        "        raise Exception('Img is not numpy and is not torch.tensor')\n",
        "    img = img.copy()\n",
        "    img = (img * 255).astype(dtype=int)\n",
        "    img[np.where(img > 200)] = 255\n",
        "    img[np.where(img <= 200)] = 0\n",
        "    img = img.reshape([256, 256])\n",
        "    img = img.astype(dtype=np.uint8)\n",
        "\n",
        "    centers = []\n",
        "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "    for contour in contours:\n",
        "        M = cv2.moments(contour)\n",
        "        if M['m00'] != 0:\n",
        "            cx = int(M['m10'] / M['m00'])\n",
        "            cy = int(M['m01'] / M['m00'])\n",
        "            centers.append([cx, cy])\n",
        "    return centers"
      ],
      "metadata": {
        "id": "3_vMvU231r4w"
      },
      "id": "3_vMvU231r4w",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "560eae99",
      "metadata": {
        "id": "560eae99"
      },
      "outputs": [],
      "source": [
        "img_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "def get_preds(img):\n",
        "    SIDE = 256\n",
        "    h, w, _ = img.shape\n",
        "    all_bears = []\n",
        "    for x in range(0, w, SIDE):\n",
        "        for y in range(0, h, SIDE):\n",
        "            x_dif = 0\n",
        "            y_dif = 0\n",
        "            if x + SIDE > w:\n",
        "                x_dif = x + SIDE - w\n",
        "            if y + SIDE > h:\n",
        "                y_dif = y + SIDE - h\n",
        "            part_img = img[y - y_dif:y+SIDE, x - x_dif:x+SIDE]\n",
        "            part_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            data = img_transforms(part_img)\n",
        "            data = torch.FloatTensor([data.numpy().tolist()])\n",
        "            if train_on_gpu:\n",
        "                data = data.cuda()\n",
        "            output = ((model(data))[0]).cpu().detach()\n",
        "            bears = find_bears(output)\n",
        "            for i in range(len(bears)):\n",
        "                bears[i][0] += x - x_dif\n",
        "                bears[i][1] += y - y_dif\n",
        "            all_bears.extend(bears)\n",
        "    return all_bears"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([], columns=['name', 'x', 'y'])\n",
        "for path in os.listdir(os.path.join(WORKING_DIR, 'arctic_with_bears/bears')):\n",
        "    img = cv2.imread(os.path.join(os.path.join(WORKING_DIR, 'arctic_with_bears/bears'), path))\n",
        "    preds = get_preds(img)\n",
        "    for pred in preds:\n",
        "        df.loc[len(df)] = [path, int(pred[0]), int(pred[1])]"
      ],
      "metadata": {
        "id": "Bywtt5oZLunC"
      },
      "id": "Bywtt5oZLunC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('out.csv', index=False)"
      ],
      "metadata": {
        "id": "dZWZTguG_y0s"
      },
      "id": "dZWZTguG_y0s",
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}