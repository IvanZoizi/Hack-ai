{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "685b32c7",
      "metadata": {
        "id": "685b32c7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cbook as cbook\n",
        "from matplotlib.path import Path\n",
        "from matplotlib.patches import PathPatch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b345dea",
      "metadata": {
        "id": "1b345dea"
      },
      "source": [
        "# shit EDA and data engineering shit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P53VdcRU_kPU",
        "outputId": "3f42ee4a-0ef3-4cb7-c718-406c21b6cf76"
      },
      "id": "P53VdcRU_kPU",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR = '/content/drive/MyDrive/find_polar_bear'"
      ],
      "metadata": {
        "id": "WzKGrrWf_jp5"
      },
      "id": "WzKGrrWf_jp5",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([], columns=['id', 'image', 'x1', 'y1', 'x2', 'y2'])\n",
        "i = 0\n",
        "for path in tqdm(os.listdir(os.path.join(WORKING_DIR, 'arctic_with_bears/masks'))):\n",
        "    new_path = os.path.join(os.path.join(WORKING_DIR, 'arctic_with_bears/masks'), path)\n",
        "    img = cv2.cvtColor(cv2.imread(new_path), cv2.COLOR_BGR2GRAY)\n",
        "    unique_colors = np.unique(img)\n",
        "    unique_colors = np.array(list(filter(lambda x: x != 0, unique_colors)))\n",
        "    rects = []\n",
        "    for unique_color in unique_colors:\n",
        "        borders = np.where(img == unique_color)\n",
        "        top, bottom = min(borders[0]), max(borders[0])\n",
        "        left, right = min(borders[1]), max(borders[1])\n",
        "        df2 = pd.DataFrame([{'id': i, 'image': path, 'x1': left, 'y1': top, 'x2': right, 'y2': bottom}], columns=df.columns)\n",
        "        df = pd.concat([df, df2])\n",
        "        i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2apIFxe_QRZ",
        "outputId": "55db63aa-2e05-48db-aa30-54c9d29a226f"
      },
      "id": "N2apIFxe_QRZ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:37<00:00,  1.06s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a8257098",
      "metadata": {
        "scrolled": false,
        "id": "a8257098"
      },
      "outputs": [],
      "source": [
        "def crop_bear(img_i,  SIDE=200):\n",
        "    img = cv2.imread(os.path.join(WORKING_DIR, f'arctic_with_bears/bears/{img_i}.JPG'))\n",
        "    if img is None:\n",
        "        img = cv2.imread(os.path.join(WORKING_DIR, f'arctic_with_bears/bears/{img_i}.jpg'))\n",
        "    mask = cv2.imread(os.path.join(WORKING_DIR, f'arctic_with_bears/masks/{img_i}.png'))\n",
        "    _, _, x1, y1, x2, y2 = list(df[df['image'] == f'{img_i}.png'].iloc[0])\n",
        "    \n",
        "    x1 = round(x1, -2) - 100 if round(x1, -2) - 100 >= 0 else 0\n",
        "    x2 = x1 + 200 if x1 + 200 <= len(img[0]) else len(img[0])\n",
        "    \n",
        "    y1 = round(y1, -2) - 100 if round(y1, -2) - 100 >= 0 else 0\n",
        "    y2 = y1 + 200 if y1 + 200 <= len(img) else len(img)\n",
        "    \n",
        "    return img[y1:y2, x1:x2], mask[y1:y2, x1:x2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "50e4b16d",
      "metadata": {
        "id": "50e4b16d"
      },
      "outputs": [],
      "source": [
        "for i in range(0, 35):\n",
        "    bear, mask = crop_bear(i)\n",
        "    cv2.imwrite(os.path.join(WORKING_DIR, f'bears_cropped/bears/{i}.jpg'), bear)\n",
        "    cv2.imwrite(os.path.join(WORKING_DIR, f'bears_cropped/masks/{i}.png'), mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c9cabbce",
      "metadata": {
        "id": "c9cabbce"
      },
      "outputs": [],
      "source": [
        "black = cv2.imread(os.path.join(WORKING_DIR, f'arctic_with_bears/masks/0.png'))\n",
        "black = black[:200, :200, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "19a6871b",
      "metadata": {
        "id": "19a6871b"
      },
      "outputs": [],
      "source": [
        "for i in range(35, 71):\n",
        "    img = cv2.imread(os.path.join(WORKING_DIR, f'arctic_no_bears/{i}.JPG'))\n",
        "    img = img[:200, :200, :]\n",
        "    cv2.imwrite(os.path.join(WORKING_DIR, f'bears_cropped/bears/{i}.jpg'), img)\n",
        "    cv2.imwrite(os.path.join(WORKING_DIR, f'bears_cropped/masks/{i}.png'), black)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60b7ae4",
      "metadata": {
        "id": "f60b7ae4"
      },
      "source": [
        "# Setting up data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83eca9f1",
      "metadata": {
        "scrolled": true,
        "id": "83eca9f1"
      },
      "outputs": [],
      "source": [
        "!pip install catalyst\n",
        "!pip install albumentations --user\n",
        "!pip show catalyst\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e0854b3a",
      "metadata": {
        "id": "e0854b3a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import collections\n",
        "import time \n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "train_on_gpu = True\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
        "\n",
        "# import albumentations as albu\n",
        "# from albumentations import torch as AT\n",
        "\n",
        "# import catalyst\n",
        "# from catalyst.data import Augmentor\n",
        "# from catalyst.dl import utils\n",
        "# from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\n",
        "from catalyst.runners import SupervisedRunner\n",
        "# from catalyst.contrib.models.segmentation import Unet\n",
        "from catalyst.callbacks import DiceCallback, EarlyStoppingCallback, CheckpointCallback\n",
        "\n",
        "#import segmentation_models_pytorch as smp\n",
        "\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import time\n",
        "import tqdm\n",
        "import random\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm as tq\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8dd34a16",
      "metadata": {
        "id": "8dd34a16"
      },
      "outputs": [],
      "source": [
        "class CloudDataset(Dataset):\n",
        "    def __init__(self, img_ids, datatype: str = 'train',\n",
        "                 transforms = transforms.Compose([\n",
        "                                transforms.ToPILImage(),\n",
        "                                transforms.Resize((256, 256)),\n",
        "                                transforms.ToTensor()]),\n",
        "                preprocessing=None):\n",
        "        \n",
        "        self.img_ids = img_ids\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(os.path.join(WORKING_DIR, f'bears_cropped/bears/{idx}.jpg'))\n",
        "        try:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        except:\n",
        "            raise IndexError\n",
        "        mask = cv2.imread(os.path.join(WORKING_DIR, f'bears_cropped/masks/{idx}.png'))\n",
        "        img = self.transforms(img)\n",
        "        mask = self.transforms(mask)[:1, :, :]\n",
        "        mask = (mask > 0.5).float()\n",
        "        if self.preprocessing:\n",
        "            preprocessed = self.preprocessing(image=img, mask=mask)\n",
        "            img = preprocessed['image']\n",
        "            mask = preprocessed['mask']\n",
        "        return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7a2526f0",
      "metadata": {
        "id": "7a2526f0"
      },
      "outputs": [],
      "source": [
        "train_ids = list(set([i for i in range(0, 71)]) - set([i for i in range(0, 71, 3)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "635daefa",
      "metadata": {
        "id": "635daefa"
      },
      "outputs": [],
      "source": [
        "num_workers = 0\n",
        "bs = 5\n",
        "train_dataset = CloudDataset(datatype='train', img_ids=train_ids)\n",
        "valid_dataset = CloudDataset(datatype='valid', img_ids=[i for i in range(0, 70, 3)])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "loaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"valid\": valid_loader\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "52ff4816",
      "metadata": {
        "id": "52ff4816"
      },
      "outputs": [],
      "source": [
        "class double_conv(nn.Module):\n",
        "    \"\"\"(conv => BN => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(nn.MaxPool2d(2), double_conv(in_ch, out_ch))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))\n",
        "        \n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256, False)\n",
        "        self.up2 = up(512, 128, False)\n",
        "        self.up3 = up(256, 64, False)\n",
        "        self.up4 = up(128, 64, False)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "69669a01",
      "metadata": {
        "id": "69669a01"
      },
      "outputs": [],
      "source": [
        "def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, activation='sigmoid'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        pr (torch.Tensor): A list of predicted elements\n",
        "        gt (torch.Tensor):  A list of elements that are to be predicted\n",
        "        eps (float): epsilon to avoid zero division\n",
        "        threshold: threshold for outputs binarization\n",
        "    Returns:\n",
        "        float: IoU (Jaccard) score\n",
        "    \"\"\"\n",
        "\n",
        "    if activation is None or activation == \"none\":\n",
        "        activation_fn = lambda x: x\n",
        "    elif activation == \"sigmoid\":\n",
        "        activation_fn = torch.nn.Sigmoid()\n",
        "    elif activation == \"softmax2d\":\n",
        "        activation_fn = torch.nn.Softmax2d()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            \"Activation implemented for sigmoid and softmax2d\"\n",
        "        )\n",
        "\n",
        "    pr = activation_fn(pr)\n",
        "\n",
        "    if threshold is not None:\n",
        "        pr = (pr > threshold).float()\n",
        "\n",
        "\n",
        "    tp = torch.sum(gt * pr)\n",
        "    fp = torch.sum(pr) - tp\n",
        "    fn = torch.sum(gt) - tp\n",
        "\n",
        "    score = ((1 + beta ** 2) * tp + eps) \\\n",
        "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + eps)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    __name__ = 'dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        return 1 - f_score(y_pr, y_gt, beta=1., \n",
        "                           eps=self.eps, threshold=None, \n",
        "                           activation=self.activation)\n",
        "\n",
        "\n",
        "class BCEDiceLoss(DiceLoss):\n",
        "    __name__ = 'bce_dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, activation='sigmoid', lambda_dice=1.0, lambda_bce=1.0):\n",
        "        super().__init__(eps, activation)\n",
        "        if activation == None:\n",
        "            self.bce = nn.BCELoss(reduction='mean')\n",
        "        else:\n",
        "            self.bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        self.lambda_dice=lambda_dice\n",
        "        self.lambda_bce=lambda_bce\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        dice = super().forward(y_pr, y_gt)\n",
        "        bce = self.bce(y_pr, y_gt)\n",
        "        return (self.lambda_dice*dice) + (self.lambda_bce* bce)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bc6ee424",
      "metadata": {
        "id": "bc6ee424"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import JaccardIndex\n",
        "\n",
        "\n",
        "def dice(img1, img2):\n",
        "    img1 = np.asarray(img1).astype(np.bool)\n",
        "    img2 = np.asarray(img2).astype(np.bool)\n",
        "\n",
        "    intersection = np.logical_and(img1, img2)\n",
        "\n",
        "    return 2.0 * intersection.sum() / (img1.sum() + img2.sum())\n",
        "\n",
        "def dice_no_threshold(\n",
        "    outputs: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    eps: float = 1e-7,\n",
        "    threshold: float = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Reference:\n",
        "    https://catalyst-team.github.io/catalyst/_modules/catalyst/dl/utils/criterion/dice.html\n",
        "    \"\"\"\n",
        "    if threshold is not None:\n",
        "        outputs = (outputs > threshold).float()\n",
        "\n",
        "    intersection = torch.sum(targets * outputs)\n",
        "    union = torch.sum(targets) + torch.sum(outputs)\n",
        "    dice = 2 * intersection / (union + eps)\n",
        "\n",
        "    return dice\n",
        "\n",
        "jaccard = JaccardIndex(num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "82cb8e3b",
      "metadata": {
        "id": "82cb8e3b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "class RAdam(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "            \n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(RAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(RAdam, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:            \n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "00b64bb7",
      "metadata": {
        "id": "00b64bb7"
      },
      "outputs": [],
      "source": [
        "model = UNet(n_channels=3, n_classes=1).float()\n",
        "train_on_gpu = True\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dc9cbd5b",
      "metadata": {
        "id": "dc9cbd5b"
      },
      "outputs": [],
      "source": [
        "criterion = BCEDiceLoss(eps=1.0, activation=None)\n",
        "optimizer = RAdam(model.parameters(), lr = 0.002)\n",
        "current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, patience=2, cooldown=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95659f09",
      "metadata": {
        "id": "95659f09"
      },
      "source": [
        "# training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf13706",
      "metadata": {
        "scrolled": true,
        "id": "ecf13706",
        "outputId": "97f91e14-3fe3-4521-fa46-82451e576ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dea3565f2e0c420bb7c84b1044028d5c",
            "ef8bf359b8d04fac952d819adae40fd4",
            "94df72f8058c4b51898a49c586f69c3e",
            "4dc31c0283bd4d4d90f0402ce5a42e11",
            "1657adafc9c945b2821419b3636126c3",
            "66997e19a36347c79855aee5f81e8c67",
            "90a57f76c8514f9aa2a595a443045c20",
            "67e8ded188a041089a6045ec7f8255db",
            "6a225b4e5fd44804925338c9e249e5e1",
            "f1aa8dc23c6f448a8f4a37117bdfdf75",
            "a68e53c68e47438b87e2699ce631956c"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s, train_loss=0]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dea3565f2e0c420bb7c84b1044028d5c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 250\n",
        "train_loss_list = []\n",
        "valid_loss_list = []\n",
        "dice_score_list = []\n",
        "lr_rate_list = []\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "train_on_gpu = True\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    dice_score = 0.0\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    bar = tq(train_loader, postfix={\"train_loss\":0.0})\n",
        "    for data, target in bar:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "#         print(output.size(), target.size())\n",
        "        loss = criterion(output, target)\n",
        "        #print(loss)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        bar.set_postfix(ordered_dict={\"train_loss\":loss.item()})\n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    del data, target\n",
        "    with torch.no_grad():\n",
        "        bar = tq(valid_loader, postfix={\"valid_loss\":0.0, \"dice_score\":0.0})\n",
        "        for data, target in bar:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average validation loss \n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "            dice_cof = dice_no_threshold(output.cpu(), target.cpu()).item()\n",
        "            dice_score +=  dice_cof * data.size(0)\n",
        "#             dice_score = jaccard(output, torch.IntTensor(target))\n",
        "            bar.set_postfix(ordered_dict={\"valid_loss\":loss.item(), \"dice_score\":dice_cof})\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "    dice_score = dice_score/len(valid_loader.dataset)\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    dice_score_list.append(dice_score)\n",
        "    lr_rate_list.append([param_group['lr'] for param_group in optimizer.param_groups])\n",
        "    \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {}  Training Loss: {:.6f}  Validation Loss: {:.6f} Dice Score: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss, dice_score))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "        valid_loss_min = valid_loss\n",
        "    \n",
        "    scheduler.step(valid_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d58a59",
      "metadata": {
        "id": "67d58a59"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot([i[0] for i in lr_rate_list])\n",
        "plt.ylabel('learing rate during training', fontsize=22)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe638825",
      "metadata": {
        "id": "fe638825"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(train_loss_list,  marker='o', label=\"Training Loss\")\n",
        "plt.plot(valid_loss_list,  marker='o', label=\"Validation Loss\")\n",
        "plt.ylabel('loss', fontsize=22)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99d47a4",
      "metadata": {
        "id": "b99d47a4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(dice_score_list)\n",
        "plt.ylabel('Dice score')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dea3565f2e0c420bb7c84b1044028d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef8bf359b8d04fac952d819adae40fd4",
              "IPY_MODEL_94df72f8058c4b51898a49c586f69c3e",
              "IPY_MODEL_4dc31c0283bd4d4d90f0402ce5a42e11"
            ],
            "layout": "IPY_MODEL_1657adafc9c945b2821419b3636126c3"
          }
        },
        "ef8bf359b8d04fac952d819adae40fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66997e19a36347c79855aee5f81e8c67",
            "placeholder": "​",
            "style": "IPY_MODEL_90a57f76c8514f9aa2a595a443045c20",
            "value": "  0%"
          }
        },
        "94df72f8058c4b51898a49c586f69c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e8ded188a041089a6045ec7f8255db",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a225b4e5fd44804925338c9e249e5e1",
            "value": 0
          }
        },
        "4dc31c0283bd4d4d90f0402ce5a42e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1aa8dc23c6f448a8f4a37117bdfdf75",
            "placeholder": "​",
            "style": "IPY_MODEL_a68e53c68e47438b87e2699ce631956c",
            "value": " 0/10 [00:00&lt;?, ?it/s, train_loss=0]"
          }
        },
        "1657adafc9c945b2821419b3636126c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66997e19a36347c79855aee5f81e8c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a57f76c8514f9aa2a595a443045c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67e8ded188a041089a6045ec7f8255db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a225b4e5fd44804925338c9e249e5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1aa8dc23c6f448a8f4a37117bdfdf75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68e53c68e47438b87e2699ce631956c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}